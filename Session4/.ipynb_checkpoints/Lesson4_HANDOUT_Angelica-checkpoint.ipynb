{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147f7d34",
   "metadata": {},
   "source": [
    "# Statistical Inference\n",
    "## Lesson overview:\n",
    "In this lesson we will go over statistical inference. We will start with one-sample tests (both for means and proportions), as well as calculating confidence intervals. Then, we will move to two-sample and paired tests. Lastly, we will also guide you to perform one-way ANOVA test, simple linear regression and multiple linear regression by using statsmodels.formula.api.\n",
    "\n",
    "By the end of this session you will be able to:\n",
    "* Use statsmodels.stats.proportion, scipy.stats, statsmodels.api and statsmodels.formula.api to perform statistical inference: one-sample tests, two-sample tests, paired data tests, one-way anova, SLR and MLR.\n",
    "* Practice creating plots for checking conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f38516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and functions\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n",
    "from scipy.stats import t, probplot, ttest_1samp, ttest_ind, ttest_rel, sem\n",
    "from statsmodels.api import qqplot, stats\n",
    "from statsmodels.formula.api import ols\n",
    "from math import sqrt\n",
    "\n",
    "# Read csv file\n",
    "coasters = pd.read_csv(\"Coasters_2015.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c668efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the data by using head()\n",
    "coasters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "473c99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the data by using describe()\n",
    "coasters.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad417f",
   "metadata": {},
   "source": [
    "### One-sample proportion z-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e15b3e",
   "metadata": {},
   "source": [
    "We will begin by performing a one-sample z-test. Recall that the purpose of this parametric test is to determine if there is a significant difference between the sample proportion and the hypothesized population proportion. Let's say we were interested in learning the true propotion of steel roller coasters in this dataset. Let's begin by finding the proportion of steel roller coaster of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e501ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Count how many rollercoasters have a steel track v/s how many have a wood track\n",
    "print( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4181d",
   "metadata": {},
   "source": [
    "Great! The proportion of steel roller coasters is ~ 0.88.\n",
    "\n",
    "However, a rollercoasters' expert suggests that during 2022 the proportion of steel roller coasters hasn't changed. Her study shows that 320 out of 355 roller coasters have a steel track.\n",
    "\n",
    "* $H_0$: $p̂$ = 0.88 ; the proportion of steel roller coasters in 2022 is 0.88\n",
    "* $H_A$: $p̂$ ≠ 0.88 ; the proportion of steel roller coasters in 2022 is different from 0.88\n",
    "\n",
    "**Check conditions:**\n",
    "* n < 10% of total population: we can assume that 355 rollercoasters is less than 10% of all roller coasters in the world.\n",
    "* randomness: we can assume that we were given a random sample of roller coasters.\n",
    "* successes vs failures : 355 * 0.88 = 312, 241 * 0.12 = 43. Both values are greater than 10.\n",
    "\n",
    "\n",
    "To test our null hypothesis, we will make use of proportions_ztest which we imported at the beginning of the notebook.\n",
    "\n",
    "**Structure:**\n",
    "* z_test, p_value = proportions_ztest(count = #, nobs = #, value = #, alternative = \"one_or_two\")\n",
    "\n",
    "**Arguments**\n",
    "* count = # ; number of successes if Null Hypothesis is True. (total observed * hypothesized proportion)\n",
    "* nobs = # ; size of observed sample\n",
    "* value = # ; observed proportion\n",
    "* alternative = \"nameOfAlternative\" ; Type of test(two-sided or one-sided)\n",
    "\n",
    "**Note**: In this case, observed corresponds to what the roller coasters expert observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store z_test and p_value\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"The z test values is: \", z_test, \". The p-value is: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb6a5a",
   "metadata": {},
   "source": [
    "Since the p-value is greater than 0.05 we fail to reject the null hypothesis. We do not have enough evidence to say that the proportion of steel roller coasters in 2022 has changed sinced 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b2c4bb",
   "metadata": {},
   "source": [
    "### Confidence Interval for proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a2b74a",
   "metadata": {},
   "source": [
    "Now let's calculate our confidence interval for steel track proportion for the true population **using our 2015 data** (212 steel roller coasters/241 roller coasters in total). In order to do so, we will use proportion_confint which we imported at the beginning of the notebook.\n",
    "\n",
    "**Structure:**\n",
    "* conf_prop = proportion_confint(count = #, nobs = #, alpha = #)\n",
    "\n",
    "**Arguments:**\n",
    "* count = # ; number of successes\n",
    "* nobs = # ; size of sample\n",
    "* alpha = # ; the desired significance level (1 - confidence interval from 0 to 1)\n",
    "\n",
    "**Check conditions:**\n",
    "* n < 10% of total population: we can assume that 241 rollercoasters is less than 10% of all rollercoasters in the world.\n",
    "* randomness: we can assume that we were given a random sample of rollercoasters.\n",
    "* successes vs failures : 241 * 0.88 = 212, 241 * 0.12 = 29. Both values are greater than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confidence interval and store in conf_prop\n",
    "\n",
    "\n",
    "# Print confidence interval\n",
    "print( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70913665",
   "metadata": {},
   "source": [
    "We are 95% confident that between 83% and 92% of the roller coasters in the world have a steel track."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93c66db",
   "metadata": {},
   "source": [
    "## Two-Sample z-Test\n",
    "\n",
    "If we wanted to test the difference between two proportions, we might want to conduct a two-sample z-test. A two-proportion z-test allows us to find the true difference between two proportions for two separate groups. In our example, we will use the titanic dataset to determine if there is a significant difference in the proportion of people who survived depending on their gender. \n",
    "\n",
    "$H_0$: $p_1$ - $p_2$ = 0\n",
    "\n",
    "$H_A$: $p_1$ ≠ $p_2$\n",
    "\n",
    "Let's begin by familiarizing ourselves with this new dataset, which gives us the information of ~2200 passengers. Originally, the Titanic had 2400 passengers and crew on board so we will test for its true population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "titanic = pd.read_csv(\"titanic_2020.txt\", sep = \"\\t\")\n",
    "\n",
    "# Take a look at the data\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73736dd2",
   "metadata": {},
   "source": [
    "Before completing our two-proportion z-test, let's remember to check conditions. Recall that in this case, we must check the randomization condition, independent groups assumption, and the success/failure condition. Since we are working a dataset that describes the individuals on the titanic ship, we can say that it likely meets all conditions and proceed with caution. Let's move onto look at a contingency table, which will inform us of the proportions that we will need to put to the test. Remember that we learned how to make contingency tables in our last lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a contingency table comparing Gender and Survived with totals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf429d1",
   "metadata": {},
   "source": [
    "Now that we have made our contingency table, we know what values for our proportions that we will need to test. We will use the function *proportions_ztest( )* from the statsmodels.stats.proportion library. This function requires two lists of equal length that contain the values from our contingency table. Since we are trying to determine if there is a significant difference in the proportions of people who survived depending on their gender, we will create two lists that store the values of people who surived per gender and then the total amount of people per gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc882ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the amount of people who survived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f9da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "print(\"p-values:\", p)\n",
    "print(\"t-test:\", stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32704c6c",
   "metadata": {},
   "source": [
    "We can instruct Python to determine for us whether or not the P Value for our t-test is small enough to reject the null hypothesis using an if-else statement. Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f6827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use 0.05 or 5% as the significance level of alpha.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b7a9ce",
   "metadata": {},
   "source": [
    "After performing this two-sample z-test and obtaining a p-value of approximately 5.64e-108, we will reject the null hypothesis that the proportion of people who survived depending on their gender is equal. Thus, gender is likely an important variable in understanding the breakdown of people who survived the titanic shipwreck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e145160",
   "metadata": {},
   "source": [
    "## Two-Proportion z-interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753aab33",
   "metadata": {},
   "source": [
    "Now let's calculate the confidence interval for the difference between the proportion of females and males that survived in the Titanic.\n",
    "\n",
    "$H_0$: $p_1$ - $p_2$ = 0\n",
    "\n",
    "$H_A$: $p_1$ - $p_2$ ≠ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6856ad42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>LOST</th>\n",
       "      <th>SAVED</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>130</td>\n",
       "      <td>359</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>1366</td>\n",
       "      <td>353</td>\n",
       "      <td>1719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1496</td>\n",
       "      <td>712</td>\n",
       "      <td>2208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived  LOST  SAVED   All\n",
       "Gender                     \n",
       "Female     130    359   489\n",
       "Male      1366    353  1719\n",
       "All       1496    712  2208"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use the same contingency table\n",
    "pd.crosstab(titanic[\"Gender\"], titanic[\"Survived\"], margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1d7c5a",
   "metadata": {},
   "source": [
    "**Conditions:**\n",
    "* Independence: We can assume that within each group, individual responses are independent from each other. We can also assume that each group is independent from each other.\n",
    "* Sample size: Saved females > 10 and Saved males > 10; thus successes/failures is satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c175b",
   "metadata": {},
   "source": [
    "**Structure:**\n",
    "* confint_proportions_2indep(count1 = n1, nobs1 = obs1, count2 = n2, nobs2 = obs2, compare = \"diff\", alpha = 0.05)\n",
    "\n",
    "**Arguments:**\n",
    "* count1 = sample size for group 1\n",
    "* count2 = sample size for group 2\n",
    "* nobs1 = \"successes\" for group 1\n",
    "* nobs2 = \"successes\" for group 2\n",
    "* compare = \"diff\" ; null hypothesis if for checking whether they are different or not\n",
    "* alpha = # ; significance value (1 - confidence interval from 0 to 1)\n",
    "* correction = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2180333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform CI by using confint_proportions_2indep\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b4c69",
   "metadata": {},
   "source": [
    "We are 95% confident that the proportion of female who survided in the titanic is between 48.34% and 57% higher than the proportion of male who survived."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1511f983",
   "metadata": {},
   "source": [
    "## One-sample t-test\n",
    "\n",
    "We will begin by performing a one-sample t-test. Recall that the purpose of this parametric test is to determine if there is a significant difference between a sample mean and the hypothesized population mean. Let's say we were interested in learning the true average speed of roller coasters in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fcfb20",
   "metadata": {},
   "source": [
    "Roller coaster expert, Biddy Martin, previously stated that all roller coasters in the world actually travel at an average speed of 52 mph. Lets put her word to the test and perform a one-sample t-test to determine if this is likely to be true based on our sample. \n",
    "+ $H_0$: The average speed of roller coasters is 52 mph.\n",
    "+ $H_A$: The average speed of roller coasters is not 52 mph.\n",
    "\n",
    "Before we can put this mean to the test, let's follow our typical inference procedures and check the conditions. For a one-sample t-test we need to check the independence assumption and the normal population assumption. Our data satisifies the independence assumption because the data arises from a random sample of roller coasters.\n",
    "\n",
    "To check the normal population assumption, we need to produce a histogram of the variable in question or a Normal probability plot. Since you have learned in previous lessons how to create a histogram, we will use this as an opportunity to teach you how to create a Normal probability plot, aka a Q-Q plot. \n",
    "\n",
    "The method we will use to specify create the Q-Q plot is from the *scipy.stats* plot, called *probplot( )*. We will need to specify the following options within the parentheses of this method to generate our desired plot:\n",
    "+ data = our dataset and the variable in question, e.g. dataset_name[\"variable_name\"]\n",
    "+ plot = pyplot, this instructs Python to plot the quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a56eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Q-Q plot\n",
    "\n",
    "\n",
    "# Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be5122",
   "metadata": {},
   "source": [
    "In the Normal probability plot above, we observe some deviation from the best fit line in the upper tail. However, given that this is a rather large sample (n > 50), we are safe to use *t* methods since the data is not extremely skewed. We will, however, still proceed with caution.\n",
    "\n",
    "Using the function *ttest_1samp( )* from the *scipy.stats* library, let's perform our one-sample t-test. Within this new function, we will need to supply information for the following options:\n",
    "+ data = our dataset and the variable in question, e.g. dataset_name[\"variable_name\"]\n",
    "+ popmean = expected value in null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the results of our test to two variables\n",
    "\n",
    "\n",
    "# View the results\n",
    "print(\"P Value:\", p_value)\n",
    "print(\"t-test Value:\", t_test_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cc1c6e",
   "metadata": {},
   "source": [
    "Great work! We have just performed our first one-sample t-test. Now lets instruct Python to determine for us whether or not the P Value for our t-test is small enough to reject the null hypothesis that the average speed is 52 mph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "138e61b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "# Let's use 0.05 or 5% as the significance level of alpha.\n",
    "if p_value < 0.05:\n",
    "    \n",
    "    print(\"Reject the null hypothesis\")\n",
    "    \n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9bef90",
   "metadata": {},
   "source": [
    "Unfortunately, it appears that Biddy may have been wrong, as we have to reject the null hypothesis that the average speed of a roller coaster is 52 mph at a significant level of 0.05. What a shocker! Biddy usually gets this stuff right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ebb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We do not need to assign the output of the function ttest_1samp to two values.\n",
    "# Python automatically outputs our t-test value and p-value.\n",
    "# However, it is good practice to assign these values so we can reuse them later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec773d",
   "metadata": {},
   "source": [
    "If we were interested to see what the actual mean for the speed of roller coasters would be in this dataset, we already know how to calculate that. It turns out the mean speed is actually 55 mph, so Biddy was indeed incorrect. How unusual!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d5c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean\n",
    "\n",
    "\n",
    "# Print the result\n",
    "print(\"Mean:\", mean_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4573110",
   "metadata": {},
   "source": [
    "### Confidence Interval for one-sample mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1a0dac",
   "metadata": {},
   "source": [
    "Now let's calculate our confidence interval for average speed of roller coasters in the world using our 2015 data. In order to do so, we will use t.interval which we imported at the beginning of the notebook.\n",
    "\n",
    "**Check conditions:**\n",
    "* n >= 30 , 241 > 30\n",
    "* independence: we can assume it is a random sample, and that the average speed of one roller coaster does not affect other roller coasters\n",
    "\n",
    "**Structure:**\n",
    "* t.interval(loc = mean, scale = sd/se, df = degrees_of_freedom, alpha = conf_value)\n",
    "\n",
    "**Arguments:**\n",
    "* loc = # ; mean value from our sample\n",
    "* scale = # ; standard deviation from our sample. if you are re-sampling use standard error.\n",
    "* df = # ; degrees of freedom (n-1)\n",
    "* alpha = confidence interval from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate standard deviation for speed\n",
    "\n",
    "\n",
    "# Calculate mean for speed\n",
    "\n",
    "\n",
    "# Assign the t-interval values into t_speed\n",
    "\n",
    "\n",
    "# Print our results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe2a26",
   "metadata": {},
   "source": [
    "We are 95% confident that the average speed of rollercoasters in the world will be between 19.58 and 92 mph. Looks like a big interval, right? This could indicate that there's a lot of variability in this sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380316a7",
   "metadata": {},
   "source": [
    "## Two-sample t-test\n",
    "\n",
    "Recall that a two-sample t-test is used to determine if there is a significant difference between the sample means of two independent groups. This statistical inference method is also know as the independent samples t-test. Using the same dataset as before, lets see if the true mean speed is the same for roller coasters made of wood and steel.\n",
    "\n",
    "* $H_0$: $µ_{steel}$ - $µ_{wood}$ = 0\n",
    "* $H_0$: $µ_{steel}$ - $µ_{wood}$ ≠ 0\n",
    "\n",
    "As usual, we will start off by adding the libraries and functions we will need to use. Then, we will need to create two new dataframes from our original dataset, because the method for a two-sample t-test requires two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab621e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates the data into two new dataframes, where one is only Steel rollercoasters and the other is only Wood\n",
    "steel = coasters[coasters.Track == \"Steel\"]\n",
    "wood = coasters[coasters.Track == \"Wood\"]\n",
    "\n",
    "# Confirm this for yourself by looking at the first few rows of each dataframe\n",
    "steel.head()\n",
    "wood.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3726349",
   "metadata": {},
   "source": [
    "Now that we have completed our set-up, let's check the conditions for inference. For a two-sample t-test, we need to check the randomization condition, independent groups condition, and the nearly normal condition. Again, since this is a random sample of roller coasters, we can satisfy the randomization assumption. Independence is satisified because one roller coaster being made of wood does not impact another roller coaster's likelihood to be made of steel. To test the normality condition, let's produce two Q-Q plots: one for each track type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Q-Q plot\n",
    "\n",
    "\n",
    "# Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d8b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Q-Q plot\n",
    "\n",
    "\n",
    "# Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae759d",
   "metadata": {},
   "source": [
    "The Q-Q plot for steel rollercoasters satisfies the normality condition, even through there is some slight deviation in the upper tail. Additionally, the sample size is large enough so that this deviation would not be a major issue. The Q-Q plot for wood rollercoasters visualizes substantially less roller coasters that are made from wood, but none of the roller coasters deviate dramatically from the line of best fit. Given these observations, we can proceed to complete our statistical inference.\n",
    "\n",
    "Using the function *ttest_ind( )* from the scipy.stats library, let's perform our one-sample t-test. Within this new function, we will need to supply information for the following options:\n",
    "\n",
    "+ data = our first dataset and the variable in question, e.g. dataset_name[\"variable_name\"]\n",
    "+ data = our second dataset and the variable in question, e.g. dataset_name[\"variable_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the results of our test to two variables\n",
    "# IMPORTANT, \"ttest_ind\" requires you to specify a variable within your dataset\n",
    "\n",
    "\n",
    "# Display the results\n",
    "print(\"p-values:\", p)\n",
    "print(\"t-test:\", stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use 0.05 or 5% as the significance level of alpha.\n",
    "if p < 0.05:\n",
    "    \n",
    "    print(\"Reject the null hypothesis\")\n",
    "    \n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487f6cb9",
   "metadata": {},
   "source": [
    "At a significance level of 0.05, we fail to reject the null hypothesis that the true mean speed of the two different track types of roller coasters are the same. Let's take a look at the actual means of our data and see what we think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea27a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean speed for steel tracks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean speed for wooden tracks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a67c16",
   "metadata": {},
   "source": [
    "Some might argue that the difference between the mean speeds is substantial. However, according to our test, we lack sufficient evidence to reject the null hypothesis and state that speed changes depending on track type. Oh well. Maybe with a different sample dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3695f082",
   "metadata": {},
   "source": [
    "## Two-sample t-interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebe54c",
   "metadata": {},
   "source": [
    "Let's go ahead and calculate a confidence interval for the previous example!\n",
    "\n",
    "* $H_0$: $µ_{steel}$ - $µ_{wood}$ = 0\n",
    "* $H_0$: $µ_{steel}$ - $µ_{wood}$ ≠ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb393d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the total counts for steel v/s wood rollercoasters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6cfb19",
   "metadata": {},
   "source": [
    "**Conditions:**\n",
    "* Independence: We can assume that within each group, individual responses are independent from each other. We can also assume that each group is independent from each other.\n",
    "* Normal populations: steel has a large enough size and wood should be checked with a graph.\n",
    "\n",
    "Let's go ahead and create histograms to check the normal population assumption!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92184f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create faceted histogram with seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffa3d69",
   "metadata": {},
   "source": [
    "Awesome! Both populations seem to follow roughly normal distributions. We do have to be careful since there are some apparent outliers for steel roller coasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "661fc70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the counts in different variables. One for steel, one for wood and one for total\n",
    "\n",
    "\n",
    "# Calculate the difference in average speed for wood and steel\n",
    "\n",
    "\n",
    "# Difference in standard errors\n",
    "  # First calculate standard deviation for steel and wood separately \n",
    "\n",
    "\n",
    "  # Standard error. Refer to formula at the bottom.\n",
    "\n",
    "\n",
    "# Difference of standard error. Refer to formula at the bottom.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34df99c",
   "metadata": {},
   "source": [
    "#### Standard Error Formula:\n",
    "\n",
    "## $\\sqrt{\\frac{σ_1^2}{n_1} + \\frac{σ_2^2}{n_2}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e0c7a",
   "metadata": {},
   "source": [
    "Great! Now that we have all these values we will go ahead and put them as parameters in the t.interval formula.\n",
    "\n",
    "**Structure:**\n",
    "* t.interval(loc = avg_diff, scale = se_diff, df = degrees_of_freedom, alpha = conf_value)\n",
    "\n",
    "**Arguments:**\n",
    "* loc = # ; difference between means\n",
    "* scale = # ; standard erorr difference.\n",
    "* df = # ; degrees of freedom (n1 + n2 - 2 if pooled data or use function degreesOfFreedom for non-pooled data)\n",
    "* alpha = confidence interval from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "894e4b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def degreesOfFreedom(m_1, m_2, sd_1, sd_2, n_1, n_2):\n",
    "    df = (((sd_1**2)/n_1 + (sd_2**2)/n_2)**2)/ (((sd_1**2)/n_1)**2/(n_1-1) + ((sd_2**2)/n_2)**2/(n_2-1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc46486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degrees of freedom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e2c894b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store lower and upper boundaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb30c8",
   "metadata": {},
   "source": [
    "Since *zero is included in the confidence interval*, the true population of wood roller coasters could be either slower, faster or have the same speed as steel roller coasters, but we do not have enough evidence to determine which one of these alternatives is the right case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161b4f1",
   "metadata": {},
   "source": [
    "## Paired sample t-test\n",
    "Our next statistical inference task is to complete a paired sample t-test, or a dependent sample t-test, on our coasters dataset. Remind yourselves that a paired sample t-test checks if the mean difference between two observations of the same group is 0. These tests are particularly useful to determine the impact of a treatment in an experiment.\n",
    "\n",
    "In this example, the data comes from Dr. Chico’s introductory statistics class. Students in the class take two tests over the course of the semester. Dr. Chico gives notoriously difficult exams with the intention of motivating her students to work hard in the class and thus learn as much as possible. Dr. Chico’s theory is that the first test will serve as a “wake up call” for her students, such that when they realize how difficult the class actually is they will be motivated to study harder and earn a higher grade on the second test than they got on the first test.\n",
    "\n",
    "To determine if Dr. Chico's \"wake up call\" truly works for the true population, let's perform a paired sample t-test to determine whether or not a student's performance on the second exam is significantly different from their performance on the first exam.\n",
    "+ $H_0$: The average scores for each test will be the same.\n",
    "+ $H_A$: The average scores for each test are not the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd39ad46",
   "metadata": {},
   "source": [
    "Let's begin by importing the data and taking a look at its format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c44a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data \n",
    "Chico = pd.read_csv(\"chico_wide.csv\")\n",
    "\n",
    "# Glimpse data\n",
    "Chico.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e9982",
   "metadata": {},
   "source": [
    "Before we can begin our test, we will need to create two separate sets of data: one with the scores from the first exam and one with the scores from the second exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0defa373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores on the first exam\n",
    "exam1 = Chico['grade_test1']\n",
    "\n",
    "# Scores on the second exam\n",
    "exam2 = Chico['grade_test2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fbf20e",
   "metadata": {},
   "source": [
    "Recall that in a paired sample t-test, the conditions for inference are the paired data condition, independence, and normality. We know that the data satisfy the paired data condition because these two exam scores are dependent on a single student. Given that the data is paired, the groups are not independent, thus, here we are looking for pairwise differences. We can be certain that this data is independent because the observed differences are a representative sample from a population of interest. Additionally, one student's performance does not impact another student's performance on an exam. To check the normality condition, we can again produce our Q-Q plots to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a44902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Q-Q plot\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc47a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Q-Q plot\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68de076",
   "metadata": {},
   "source": [
    "Seeing as all of the datapoints roughly follow the line of best fit, we can assume that our data follows the normality condition. We will proceed to test our null hypothesis that Dr. Chico's theory produces no significant difference in students' performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65705781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the results of our test to two variables\n",
    "\n",
    "\n",
    "# Display the results\n",
    "print(\"p-values:\", p)\n",
    "print(\"t-test:\", stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41acc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use 0.05 or 5% as the significance level of alpha.\n",
    "if p < 0.05:\n",
    "    \n",
    "    print(\"Reject the null hypothesis\")\n",
    "    \n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f76443",
   "metadata": {},
   "source": [
    "When alpha is equal to 0.05, we reject the null hypothesis that Dr. Chico's theory produces no significant difference in students' performance. Rather, it appears that students performed significantly better on the second exam, which may be a result of Dr. Chico making the first exam particularly challenging. Thus, Dr. Chico's could be applied to other student populations and produce and improvement in their scores as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d94098",
   "metadata": {},
   "source": [
    "## One-way ANOVA\n",
    "\n",
    "In the case where we have two or multiple groups that we would like to compare at the same time, we will want to use ANOVA as our statistical inference test. ANOVA checks for a signficant difference between and within multiple groups, and it can test multiple hypotheses at once. \n",
    "\n",
    "In our example, we will analyze the backpack weight to body weight ratios of students in their first through third years of their undergraduate studies. \n",
    "+ $H_0$: There is no significant difference between the ratios of these year groups.\n",
    "+ $H_A$: There is a significant difference between the ratios of these year groups.\n",
    "\n",
    "Let's begin by familiarizing ourselves with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deffd8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data \n",
    "bp = pd.read_csv(\"Backpack.csv\")\n",
    "\n",
    "# Glimpse the data\n",
    "bp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba93e7",
   "metadata": {},
   "source": [
    "Let's check the conditions for inference for one-way ANOVA which are linearity, independence, equal variance, and normality. Our data satisfies the independence condition because one student's backpack to bodyweight ratio does not impact another student's ratio. We will produce a Normal Q-Q plot to check normality, and now we will also teach you how to create a Residuals vs. Fitted plot to check linearity and equal variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb707f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Q-Q plot\n",
    "\n",
    "\n",
    "# Display the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a210b9d",
   "metadata": {},
   "source": [
    "Based on the probability plot above, the data looks to be pretty normal with the exception of some slight deviation in the upper and lower tails. We will proceed to create the Residuals vs. Fitted plot with caution.\n",
    "\n",
    "To produce the following plot, we will need to create the model for our one-way ANOVA. In this case, we will need to articulate to Python that we are trying to understand the relationship between backpack ratios and a student's year. After fitting the model, we will then need to direct Python to calculate the fitted and residual values. After that, we will be using matplotlib.pyplot to create a scatterplot of the residuals vs. fitted points.\n",
    "\n",
    "When fitting a linear model, we will be using a new method called *ols( )* from the *statsmodels.formul.api* library. As good practice, we will assign the output to a variable. Within the parentheses, we must specify the following options:\n",
    "+ data = our dataset\n",
    "+ formula = \"dependent_variable ~ explanatory_variable\"\n",
    "+ .fit() = function written after the parentheses that instructs Python to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4491fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting linear model\n",
    "\n",
    "\n",
    "# Fitted values that predict the backpack ratio\n",
    "\n",
    "\n",
    "# Observed ratios - fitted values = residuals\n",
    "# .resid finds the residuals\n",
    "\n",
    "# Residuals vs. fitted values\n",
    "\n",
    "\n",
    "# Adds a line to more clearly see variance from 0\n",
    "\n",
    "\n",
    "# Add labels\n",
    "\n",
    "\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c5316c",
   "metadata": {},
   "source": [
    "The fitted vs. residuals plot demonstrates that the conditions for linearity and equal variance are not satisifed by this dataset. The data points are showing clear patterns and do not fall around the zero line. For the sake of learning how to do ANOVA, we will continue without taking the results of the test to mean much.\n",
    "\n",
    "Since our data is set-up and we have checked conditions, we can begin our one-way ANOVA test to see if backpack to bodyweight ratio changes depending on a student's year. We will generate a one-way ANOVA table using the function *stats.anova_lm* from the *statsmodels.api* library. As good practice, we will assign our table to a variable, and within the parentheses, specify the following options:\n",
    "+ model = the model name assigned when we fit the model above\n",
    "+ typ = the type of ANOVA test to perform, e.g. \"1\" for one-way ANOVA, \"2\" for two-way ANOVA, and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8bc8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ANOVA table\n",
    "\n",
    "\n",
    "# Display the ANOVA table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daba04f",
   "metadata": {},
   "source": [
    "Just now, we have tested the hypothesis that there is no difference between the mean backpack ratio for students of different years in their undergraduate studies. Our results show us that we fail to reject the null hypothesis at a significance level of 0.05, because the p-value for our F-statistic is 0.47. Meaning, there is no significant difference between the backpack to bodyweight ratios for students of different class years. However, given that our data fails the conditions for one-way ANOVA's inference, we should not take these results as fact and try again with a better dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84fe578",
   "metadata": {},
   "source": [
    "## Inference for Linear Regression\n",
    "Let's learn how to perform inference with linear regression! We will use a dataset from the world health organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8caa528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data set\n",
    "who = pd.read_csv(\"world_health.csv\")\n",
    "\n",
    "# Take a look at the data set\n",
    "who.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6cf6c5",
   "metadata": {},
   "source": [
    "Is there an association between schooling and life expectancy after adjusting for relevant confounders?\n",
    "* $H_0$: there's no association between schooling and life expectancy\n",
    "* $H_A$: there's an association between schooling and life expectancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8321b52c",
   "metadata": {},
   "source": [
    "To plot some of the graphs for checking conditions and asummptions, we must fit our data into our linear model. We will use ols which we imported at the beginning of the notebook.\n",
    "\n",
    "**Arguments:**\n",
    "* data = dataframe\n",
    "* formula = \"dependent ~ independent\" \n",
    "\n",
    "After writing our arguments, we will type .fit()\n",
    "\n",
    "* ols(data = dataframe, formula = \"dependent ~ independent\").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afaf9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd577046",
   "metadata": {},
   "source": [
    "### Linearity\n",
    "There are different ways of checking linearity. In order to put in practice what we've previously learned we will use a scatterplot to check if the relationship between life_exp and schooling is truly linear or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "195b3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatterplot using lmplot from seaborn.\n",
    "\n",
    "# Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e6ff1",
   "metadata": {},
   "source": [
    "We can say that the scatterplot follows a moderately weak, positive linear associaiton."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca3e15",
   "metadata": {},
   "source": [
    "### Independence and Equal Variance\n",
    "To check independence and equal variance we will use a scatterplot. More specifically, we will plot the fitted and residual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b66a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fitted model to store fitted and residual values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e240911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatterplot using fitted and residual values\n",
    "\n",
    "\n",
    "# Add horizontal line\n",
    "\n",
    "\n",
    "# Show plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19316320",
   "metadata": {},
   "source": [
    "Awesome! we can see that the values seem to be randomly scattered around the 0 axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e859e358",
   "metadata": {},
   "source": [
    "### Normality \n",
    "To check normality we will use qqplot, which we imported at the beginning.\n",
    "\n",
    "**Arguments for qqplot:**\n",
    "* data = modelName.resid \n",
    "* line = \"s\" ; standardized line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad78d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the qqplot. Note that there's a semi-colon at the end, which is to avoid jupyternotebook from returning  \n",
    "\n",
    "\n",
    "# Show plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6899bdf5",
   "metadata": {},
   "source": [
    "The end and beginning of the line seem to fall out of the red line, so we will proceed with caution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aba7b9",
   "metadata": {},
   "source": [
    "Great! our conditions have been satisfied. Let's look at the summary of the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be8abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89a05a6",
   "metadata": {},
   "source": [
    "Schooling has a positive association of 2.1, with a standard error of 0.034 , with a t-ratio of 60 which gives a p-value < 0.05, corresponding to a 95% confident interval for the beta coefficient between 2.035 and 2.172.\n",
    "\n",
    "We can reject the null hypothesis, since we have enough evidence to say that there is a positive association between schooling and life expectancy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9322cb",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76520d5",
   "metadata": {},
   "source": [
    "Now, what if we consider a third variable?\n",
    "\n",
    "* $H_0$ : there's no difference between country status and country's life expectancy, when adjusting for schooling\n",
    "* $H_A$ : there's a difference between country status in country's life expectancy, when adjusting for schooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a06826d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will fit the model. We added a second independent variable, status. As this variable is categorical,\n",
    "# we must add a C before its name.\n",
    "\n",
    "# formula = \"dep_var ~ ind_var1 + C(ind_var2)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87743b0",
   "metadata": {},
   "source": [
    "Now, let's check conditions. This is pretty much the same process we did before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ac31d5",
   "metadata": {},
   "source": [
    "### Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0392c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lmplot with schooling and life_exp. We will add the parameter hue to see how it changes by status.\n",
    "\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf8505e",
   "metadata": {},
   "source": [
    "Great! Both groups seem to follow a moderately weak, positive, linear association."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4aaa2",
   "metadata": {},
   "source": [
    "### Independence and Equal Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b5032c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two grids: one for developing and one for developed. \n",
    "\n",
    "\n",
    "# Map the residual plots onto the grids.\n",
    "\n",
    "\n",
    "# Set labels. See extra material for a more thorough explanation of this step.\n",
    "\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee61e9",
   "metadata": {},
   "source": [
    "Awesome! Both graphs seem to be randomly scattered around the 0 axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75708966",
   "metadata": {},
   "source": [
    "### Normal Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a69215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph qqplot by using model2.resid\n",
    "\n",
    "\n",
    "# Show graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1372366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph qqplot by using model2.resid\n",
    "\n",
    "\n",
    "# Show graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b703b",
   "metadata": {},
   "source": [
    "As also seen in the simple linear regression example, the end and beginning of the line seem to fall out of the red line, so we will proceed with caution. Now, let's look at the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f0c3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model2 summary\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585755c0",
   "metadata": {},
   "source": [
    "Since the p-value < 0.05 we can reject the null hypothesis. Compared to developed countries, countries in development have a lower life expectancy average. In conclusion, there's an association between schooling and life expectency when considering both developed and in development countries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13211a",
   "metadata": {},
   "source": [
    "Let's predict the life expectancy for a new country. Let's say that this country has an average of 12 years of schooling and it's a developed country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5e407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values from the table\n",
    "intercept = \n",
    "st_coef = \n",
    "sc_coef = \n",
    "exp = intercept + sc_coef * 12 - 3 * 0\n",
    "\n",
    "# Print results\n",
    "print(\"The life expenctancy is: \" , exp, \" years.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8697d3f4",
   "metadata": {},
   "source": [
    "We could also create a function to make this process easier and faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a15771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function and specify our arguments (the values that change)\n",
    "def life_expectancy(schooling , status):\n",
    "    exp = 48.66 + 1.93 * schooling - 3 * status\n",
    "    print(\"The life expectancy is: \" , exp, \" years.\")\n",
    "\n",
    "# Call function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07543ef5",
   "metadata": {},
   "source": [
    "If we recall our scatterplot, we can see that the obtained value makes sense! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff981482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproduce scatterplot\n",
    "sns.lmplot(data = who, x = \"schooling\", y = \"life_exp\", hue = \"Status\")\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe3b3c",
   "metadata": {},
   "source": [
    "## Tips\n",
    "* Fit the linear regression model first! You will need it to create some of the graphs.\n",
    "* Assign models and variables to clear and concise names.\n",
    "* Keep your code organized. \n",
    "* Don't forget to import functions and libraries!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a832bc12",
   "metadata": {},
   "source": [
    "## References\n",
    "* https://www.sfu.ca/~mjbrydon/tutorials/BAinPy/09_regression.html\n",
    "* https://research.library.gsu.edu/c.php?g=844869&p=7657842\n",
    "* https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704-ep713_multivariablemethods/bs704-ep713_multivariablemethods2.html\n",
    "+ https://brendanhcullen.github.io/psy611/labs/lab-9.html#data\n",
    "+ https://www.reneshbedre.com/blog/anova.html\n",
    "+ Python Data Analysis - Third Edition. (2019) 2022. Jupyter Notebook. Packt. https://github.com/PacktPublishing/Python-Data-Analysis-Third-Edition/blob/e1cd8029a1830fe5ecc86379ab361d215e71f036/Chapter05/HR_comma_sep.csv.\n",
    "+ Agresti, Alan, and Maria Kateri. 2021. Foundations of Statistics for Data Scientists: With R and Python. CRC Press.\n",
    "+ De Veaux, Richard D., Paul F. Velleman, and David E. Bock. 2022. Intro Stats. Sixth Edition. Pearson Education, Inc.\n",
    "+ “STAT 2: Modeling with Regression and ANOVA 2E | Student Resources.” n.d. Accessed July 22, 2022. https://www.macmillanlearning.com/studentresources/college/collegebridgepage/stat22e.html.\n",
    "+ Sunel, Khuzema. 2020. “Statistical Inference in Python Using Pandas, NumPy — Part I.” Medium. August 11, 2020. https://towardsdatascience.com/statistical-inference-in-pyhton-using-pandas-numpy-part-i-c2ac0320dffe.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
